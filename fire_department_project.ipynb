{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean4\\AppData\\Local\\Temp\\ipykernel_28812\\1785054242.py:7: DtypeWarning: Columns (19,20,25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fire_df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sodapy import Socrata\n",
    "\n",
    "file_path = \"./Fire_Department_Calls_for_Service.csv\"\n",
    "if os.path.isfile(file_path):\n",
    "    fire_df = pd.read_csv(file_path)\n",
    "else:\n",
    "    # if file does not exist, then get the data. This may take a long time (IE 30mins)\n",
    "    client = Socrata(\"data.sfgov.org\", None)\n",
    "    # Get 1 million results\n",
    "    amount = (10**3)*1000\n",
    "    results = client.get(\"nuek-vuh3\", limit=(amount))\n",
    "    fire_df = pd.DataFrame.from_records(results)\n",
    "    fire_df.to_csv(file_path)\n",
    "    fire_df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m location \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m(| |\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m, location)\n\u001b[0;32m     14\u001b[0m location \u001b[39m=\u001b[39m Point(\u001b[39mfloat\u001b[39m(location[\u001b[39m3\u001b[39m]), \u001b[39mfloat\u001b[39m(location[\u001b[39m2\u001b[39m]))\n\u001b[1;32m---> 15\u001b[0m data \u001b[39m=\u001b[39m Daily(location, start, end)\n\u001b[0;32m     16\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfetch()\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m keys \u001b[39min\u001b[39;00m new_data:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\meteostat\\interface\\daily.py:98\u001b[0m, in \u001b[0;36mDaily.__init__\u001b[1;34m(self, loc, start, end, model, flags)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     89\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     90\u001b[0m     loc: Union[pd\u001b[39m.\u001b[39mDataFrame, Point, \u001b[39mlist\u001b[39m, \u001b[39mstr\u001b[39m],  \u001b[39m# Station(s) or geo point\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m \n\u001b[0;32m     97\u001b[0m     \u001b[39m# Initialize time series\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_time_series(loc, start, end, model, flags)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\meteostat\\interface\\timeseries.py:170\u001b[0m, in \u001b[0;36mTimeSeries._init_time_series\u001b[1;34m(self, loc, start, end, model, flags)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flags \u001b[39m=\u001b[39m flags\n\u001b[0;32m    169\u001b[0m \u001b[39m# Get data for all weather stations\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m    172\u001b[0m \u001b[39m# Load source flags through map file\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39m# if flags are explicitly requested or\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m# model data is excluded\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m flags \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m model:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\meteostat\\interface\\meteodata.py:127\u001b[0m, in \u001b[0;36mMeteoData._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m     datasets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_datasets()\n\u001b[0;32m    126\u001b[0m     \u001b[39m# Data Processings\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m processing_handler(\n\u001b[0;32m    128\u001b[0m         datasets, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocesses, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreads\n\u001b[0;32m    129\u001b[0m     )\n\u001b[0;32m    131\u001b[0m \u001b[39m# Empty DataFrame\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_types])\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\meteostat\\core\\loader.py:59\u001b[0m, in \u001b[0;36mprocessing_handler\u001b[1;34m(datasets, load, cores, threads)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# Single-thread processing\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m---> 59\u001b[0m         output\u001b[39m.\u001b[39mappend(load(\u001b[39m*\u001b[39;49mdataset))\n\u001b[0;32m     61\u001b[0m \u001b[39m# Remove empty DataFrames\u001b[39;00m\n\u001b[0;32m     62\u001b[0m filtered \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m df: df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39msize \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, output))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\meteostat\\interface\\meteodata.py:54\u001b[0m, in \u001b[0;36mMeteoData._load_data\u001b[1;34m(self, station, year)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m# Check if file in cache\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_age \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m file_in_cache(path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_age):\n\u001b[0;32m     52\u001b[0m \n\u001b[0;32m     53\u001b[0m     \u001b[39m# Read cached data\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(path)\n\u001b[0;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m     \u001b[39m# Get data from Meteostat\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     df \u001b[39m=\u001b[39m load_handler(\n\u001b[0;32m     60\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint, file, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_columns, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_types, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_dates\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\pickle.py:208\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    206\u001b[0m         \u001b[39m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mWarning\u001b[39;00m)\n\u001b[1;32m--> 208\u001b[0m         \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39mload(handles\u001b[39m.\u001b[39mhandle)\n\u001b[0;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# e.g.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m pc\u001b[39m.\u001b[39mload(handles\u001b[39m.\u001b[39mhandle, encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\numpy\\core\\numeric.py:1874\u001b[0m, in \u001b[0;36m_frombuffer\u001b[1;34m(buf, dtype, shape, order)\u001b[0m\n\u001b[0;32m   1866\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1869\u001b[0m _fromfunction_with_like \u001b[39m=\u001b[39m array_function_dispatch(\n\u001b[0;32m   1870\u001b[0m     _fromfunction_dispatcher\n\u001b[0;32m   1871\u001b[0m )(fromfunction)\n\u001b[1;32m-> 1874\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_frombuffer\u001b[39m(buf, dtype, shape, order):\n\u001b[0;32m   1875\u001b[0m     \u001b[39mreturn\u001b[39;00m frombuffer(buf, dtype\u001b[39m=\u001b[39mdtype)\u001b[39m.\u001b[39mreshape(shape, order\u001b[39m=\u001b[39morder)\n\u001b[0;32m   1878\u001b[0m \u001b[39m@set_module\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1879\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misscalar\u001b[39m(element):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# import matplotlib.pyplot as plt\n",
    "from meteostat import Point, Daily\n",
    "import re\n",
    "\n",
    "new_data = {\"tavg\":[],  \"tmin\":[],  \"tmax\":[], \"prcp\":[], \"snow\":[], \"wdir\":[], \"wspd\":[], \"wpgt\":[], \"pres\":[], \"tsun\":[]}\n",
    "count = 0\n",
    "for index, row in fire_df.iterrows():\n",
    "    try:\n",
    "        count += 1\n",
    "        if count % 100000 == 0:\n",
    "            print(count)\n",
    "        date = row[\"Call Date\"].split(\"/\")\n",
    "        start = datetime(int(date[2]), int(date[0]), int(date[1]))\n",
    "        end = start\n",
    "        location = str(row[\"case_location\"])\n",
    "        location = re.split(r'\\(| |\\)', location)\n",
    "        location = Point(float(location[3]), float(location[2]))\n",
    "        data = Daily(location, start, end)\n",
    "        data = data.fetch()\n",
    "        for keys in new_data:\n",
    "            new_data[keys].append(data[keys][0])\n",
    "    except Exception as e:\n",
    "        for keys in new_data:\n",
    "            new_data[keys].append(None)\n",
    "for keys in new_data:\n",
    "    fire_df[keys] = new_data[keys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_df.drop(fire_df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "fire_df.to_csv(\"./Fire_Department_Calls_for_Service_weather.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
