{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if Spark Installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspark installed, version 3.2.1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pyspark\n",
    "    print (\"pyspark installed, version\", pyspark.__version__)\n",
    "except ImportError:\n",
    "    print (\"pyspark is not installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName('SparkExample').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data\n",
    "* header: If the CSV has a header\n",
    "* inferSchema: Tell Spark to infer the shcema, otherwise have to specify schema myself. If no schema specified, then everything is set as a string\n",
    "* na.strings: If there are empty or null strings, then it is helpful to specify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
    "# columns = [\"language\",\"count\"]\n",
    "# df = spark.createDataFrame(data).toDF(*columns)\n",
    "\n",
    "data = spark.read.option(\"header\",True).option(\"inferSchema\", True).option(\"na.strings\", \"null\").csv(\"file:///Users/Sean4/Desktop/COMP-261/Fire_Department_Calls_for_Service.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing Data\n",
    "* df.show(): Shows the first few lines of the dataset\n",
    "* df.printSchema(): Prints out the schema of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------------+------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+----------------------+--------------------+-----------------+-------------+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+------------------------------------+-------------+--------------------+----------------------+\n",
      "|Call Number|Unit ID|Incident Number|   Call Type| Call Date|Watch Date|       Received DtTm|          Entry DtTm|       Dispatch DtTm|       Response DtTm|       On Scene DtTm|Transport DtTm|Hospital DtTm|Call Final Disposition|      Available DtTm|          Address|         City|Zipcode of Incident|Battalion|Station Area| Box|Original Priority|Priority|Final Priority|ALS Unit|Call Type Group|Number of Alarms|Unit Type|Unit sequence in call dispatch|Fire Prevention District|Supervisor District|Neighborhooods - Analysis Boundaries|        RowID|       case_location|Analysis Neighborhoods|\n",
      "+-----------+-------+---------------+------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+----------------------+--------------------+-----------------+-------------+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+------------------------------------+-------------+--------------------+----------------------+\n",
      "|  221210313|    E36|       22054955|Outside Fire|05/01/2022|04/30/2022|05/01/2022 02:58:...|05/01/2022 02:59:...|05/01/2022 02:59:...|05/01/2022 03:01:...|05/01/2022 03:02:...|          null|         null|                  Fire|05/01/2022 03:05:...|GOUGH ST/GROVE ST|San Francisco|              94102|      B02|          36|3265|                3|       3|             3|    true|           Fire|               1|   ENGINE|                             1|                       2|                  5|                        Hayes Valley|221210313-E36|POINT (-122.42316...|                     9|\n",
      "+-----------+-------+---------------+------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+----------------------+--------------------+-----------------+-------------+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+------------------------------------+-------------+--------------------+----------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print DataFrame\n",
    "data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Call Number: integer (nullable = true)\n",
      " |-- Unit ID: string (nullable = true)\n",
      " |-- Incident Number: integer (nullable = true)\n",
      " |-- Call Type: string (nullable = true)\n",
      " |-- Call Date: string (nullable = true)\n",
      " |-- Watch Date: string (nullable = true)\n",
      " |-- Received DtTm: string (nullable = true)\n",
      " |-- Entry DtTm: string (nullable = true)\n",
      " |-- Dispatch DtTm: string (nullable = true)\n",
      " |-- Response DtTm: string (nullable = true)\n",
      " |-- On Scene DtTm: string (nullable = true)\n",
      " |-- Transport DtTm: string (nullable = true)\n",
      " |-- Hospital DtTm: string (nullable = true)\n",
      " |-- Call Final Disposition: string (nullable = true)\n",
      " |-- Available DtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode of Incident: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- Station Area: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- Original Priority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- Final Priority: integer (nullable = true)\n",
      " |-- ALS Unit: boolean (nullable = true)\n",
      " |-- Call Type Group: string (nullable = true)\n",
      " |-- Number of Alarms: integer (nullable = true)\n",
      " |-- Unit Type: string (nullable = true)\n",
      " |-- Unit sequence in call dispatch: integer (nullable = true)\n",
      " |-- Fire Prevention District: string (nullable = true)\n",
      " |-- Supervisor District: string (nullable = true)\n",
      " |-- Neighborhooods - Analysis Boundaries: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- case_location: string (nullable = true)\n",
      " |-- Analysis Neighborhoods: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6098235, 35)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count(), len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------+\n",
      "|summary|       City|   Number of Alarms|\n",
      "+-------+-----------+-------------------+\n",
      "|  count|    6089196|            6098235|\n",
      "|   mean|       null|  1.004956680088583|\n",
      "| stddev|       null|0.09595203175420591|\n",
      "|    min|         AI|                  1|\n",
      "|    max|Yerba Buena|                  5|\n",
      "+-------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe([\"City\",\"Number of Alarms\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|         City|  count|\n",
      "+-------------+-------+\n",
      "|           SF|3351970|\n",
      "|San Francisco|2622094|\n",
      "|SAN FRANCISCO|  42631|\n",
      "|     Presidio|  14091|\n",
      "|           TI|  13783|\n",
      "|Treasure Isla|  12840|\n",
      "|           PR|   9949|\n",
      "|          SFO|   9399|\n",
      "|         null|   9039|\n",
      "|  Yerba Buena|   2261|\n",
      "+-------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"City\").count().orderBy(\"count\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6046565\n",
      "832949\n"
     ]
    }
   ],
   "source": [
    "print(data.count())\n",
    "condition1 = (data.Priority.isNotNull()) | (data[\"Final Priority\"].isNotNull())\n",
    "condition2 = data.City != \"SAN FRANCISCO\"\n",
    "data = data.filter(condition1).filter(condition2)\n",
    "data = data.na.drop(\"any\")\n",
    "print(data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'condition2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17124\\2503835060.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcondition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Incident Number\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Zipcode of Incident\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Number of Alarms\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unit sequence in call dispatch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdata2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"any\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdata2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'condition2' is not defined"
     ]
    }
   ],
   "source": [
    "# Prime the data\n",
    "from pyspark.sql.types import DoubleType\n",
    "data2 = data.withColumn(\"Incident Number\", data[\"Incident Number\"].cast(DoubleType()))\n",
    "data2 = data.withColumn(\"Number of Alarms\", data[\"Number of Alarms\"].cast(DoubleType()))\n",
    "data2 = data.withColumn(\"Unit sequence in call dispatch\", data[\"Unit sequence in call dispatch\"].cast(DoubleType()))\n",
    "data2 = data.withColumn(\"Zipcode of Incident\", data[\"Zipcode of Incident\"].cast(DoubleType()))\n",
    "condition = (data2[\"Incident Number\"].isNotNull()) | (data2[\"Zipcode of Incident\"].isNotNull()) | (data2[\"Number of Alarms\"].isNotNull()) | (data2[\"Unit sequence in call dispatch\"].isNotNull())\n",
    "data2 = data2.na.drop(\"any\")\n",
    "data2 = data2.filter(condition).filter(condition2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "inputcols = [\"Incident Number\",  \"Number of Alarms\", \"Unit sequence in call dispatch\"]\n",
    "assembler = VectorAssembler(inputCols= inputcols,\n",
    "                            outputCol = \"predictors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assembler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17124\\3173046304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'assembler' is not defined"
     ]
    }
   ],
   "source": [
    "predictors = assembler.transform(data2)\n",
    "predictors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17124\\3111364066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Zipcode of Incident\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictors' is not defined"
     ]
    }
   ],
   "source": [
    "model_data = predictors.select(\"predictors\", \"Zipcode of Incident\")\n",
    "model_data.show(5,truncate=False)\n",
    "train_data,test_data = model_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(\n",
    "    featuresCol = 'predictors', \n",
    "    labelCol = 'Zipcode of Incident')\n",
    "lrModel = lr.fit(train_data)\n",
    "pred = lrModel.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean4\\anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----------------+\n",
      "|          predictors|Zipcode of Incident|       prediction|\n",
      "+--------------------+-------------------+-----------------+\n",
      "|[2.0100387E7,1.0,...|            94109.0|94112.16053474919|\n",
      "|[2.0100397E7,1.0,...|            94110.0|94113.83330224053|\n",
      "|[2.0100414E7,1.0,...|            94133.0|94113.83330321994|\n",
      "|[2.0100432E7,1.0,...|            94124.0|94112.16053734176|\n",
      "|[2.010044E7,1.0,2.0]|            94114.0|94113.83330471787|\n",
      "+--------------------+-------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.write.option(\"header\",\"true\").csv(\"/tmp/spark_output/Fire_Department_Calls_for_Service.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
